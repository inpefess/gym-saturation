{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a24898f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# saturation prover environment can be created\n",
    "# as any other OpenAI Gym environment\n",
    "import gym\n",
    "import os\n",
    "\n",
    "# it's obligatory to set the maximal number of steps of saturation algorithm\n",
    "# and the folder where (TPTP)[http://tptp.org/] archive was unpacked\n",
    "tptp_folder = os.path.join(os.environ[\"HOME\"], \"Downloads/TPTP-v7.4.0/\")\n",
    "env = gym.make(\n",
    "    \"gym_saturation:saturation-v0\",\n",
    "    step_limit=20,\n",
    "    tptp_folder=tptp_folder\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b7ba583",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GEO156-1.p\n",
      "{'class': 'Literal', 'negated': False, 'atom': {'class': 'Predicate', 'name': 'equidistant', 'arguments': [{'class': 'Variable', 'name': 'X0'}, {'class': 'Variable', 'name': 'X1'}, {'class': 'Variable', 'name': 'X1'}, {'class': 'Variable', 'name': 'X0'}]}}\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]\n",
      "[{'class': 'Clause', 'literals': [{'class': 'Literal', 'negated': False, 'atom': {'class': 'Predicat\n"
     ]
    }
   ],
   "source": [
    "# to make results reproducible, let's set the seed\n",
    "print(env.seed(3))\n",
    "# when resettig the environment one may pass an optional argument ---\n",
    "# a name of an exact problem from TPTP\n",
    "# (if omitted, a problem will be chosen at random)\n",
    "# parsing is done with `lark` package which sometimes might be slow\n",
    "# reimplementing parsing in a faster language than Python might help\n",
    "state = env.reset()\n",
    "# during the reset a problem is chosen at random\n",
    "print(os.path.basename(env.problem))\n",
    "# state is a list of dictionaries, representing logical clauses\n",
    "print(state[0][\"literals\"][0])\n",
    "# possible actions are indices of not processed clauses from the state\n",
    "print(env.action_space)\n",
    "# only \"ansi\" rendering method is implemented\n",
    "# it returns a JSON string representing the state\n",
    "print(env.render(\"ansi\")[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aaca074a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# let's define policy which choses the smallest logical clause as\n",
    "# \"given clause\" for saturation algorithm step\n",
    "from operator import itemgetter\n",
    "from typing import List\n",
    "\n",
    "from gym_saturation.grammar import Clause\n",
    "from gym_saturation.logic_ops.utils import clause_length\n",
    "from gym_saturation.parsing.json_grammar import dict_to_clause\n",
    "\n",
    "\n",
    "def policy(state: List[Clause]) -> int:\n",
    "    \"\"\"\n",
    "    :param state: a list of clauses\n",
    "    :returns: the index of the clause with minimal length\n",
    "    \"\"\"\n",
    "    return min(\n",
    "        [\n",
    "            (i, clause_length(dict_to_clause(clause)))\n",
    "            for i, clause in enumerate(state)\n",
    "            if not clause[\"processed\"]\n",
    "        ],\n",
    "        key=itemgetter(1),\n",
    "    )[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b018e9a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 14\n"
     ]
    }
   ],
   "source": [
    "# a typical episode with a constant policy\n",
    "# here we fix the problem by passing an optional argument\n",
    "state = env.reset(\n",
    "    problem=os.path.join(tptp_folder, \"Problems\", \"SET\", \"SET001-1.p\")\n",
    ")\n",
    "done = False\n",
    "total_reward = 0\n",
    "step_count = 0\n",
    "while not done:\n",
    "    action = policy(state)\n",
    "    state, reward, done, info = env.step(action)\n",
    "    total_reward += reward\n",
    "    step_count += 1\n",
    "# the proof here consists of only three steps\n",
    "# but a na√Øve clause size policy finds it only after 14 steps\n",
    "# a trained DL policy might have done better\n",
    "print(total_reward, step_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45343ba0",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "argv": [
    "python",
    "-m",
    "ipykernel_launcher",
    "-f",
    "{connection_file}"
   ],
   "display_name": "Python 3",
   "env": null,
   "interrupt_mode": "signal",
   "language": "python",
   "metadata": null,
   "name": "python3"
  },
  "name": "example.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
