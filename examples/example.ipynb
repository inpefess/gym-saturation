{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b643990",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# saturation prover environment can be created\n",
    "# as any other OpenAI Gym environment\n",
    "import gym\n",
    "import os\n",
    "from glob import glob\n",
    "import sys\n",
    "if sys.version_info.major == 3 and sys.version_info.minor >= 9:\n",
    "    from importlib.resources import files\n",
    "else:\n",
    "    from importlib_resources import files\n",
    "\n",
    "# this example uses package's resources\n",
    "# one can indicate the path to unpacked (TPTP)[http://tptp.org/] instead\n",
    "# it's obligatory to set the maximal number of steps of saturation algorithm\n",
    "# and the list of problems. Here are CNF problems from TPTP\n",
    "problem_list = sorted(glob(\n",
    "    os.path.join(\n",
    "        files(\n",
    "            \"gym_saturation\"\n",
    "        ).joinpath(\"resources/TPTP-mock\"),\n",
    "        \"Problems/*/*-*.p\"\n",
    "    )\n",
    "))\n",
    "env = gym.make(\n",
    "    \"gym_saturation:saturation-v0\",\n",
    "    step_limit=100,\n",
    "    problem_list=problem_list\n",
    ").unwrapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d22f054a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "# to make results reproducible, let's set the seed\n",
    "print(env.seed(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a392607",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# when resettig the environment one may pass an optional argument ---\n",
    "# a name of an exact problem from TPTP\n",
    "# (if omitted, a problem will be chosen at random)\n",
    "# parsing is done with `lark` package which sometimes might be slow\n",
    "# reimplementing parsing in a faster language than Python might help\n",
    "obs = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77e842c1",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnf(b_equals_bb, hypothesis, equal_sets(b, bb)).\n",
      "cnf(element_of_b, hypothesis, member(element_of_b, b)).\n",
      "cnf(prove_element_of_bb, hypothesis, ~member(element_of_b, bb)).\n",
      "cnf(membership_in_subsets, hypothesis, ~member(X0, X1) | ~subset(X1, X2) | member(X0, X2)).\n",
      "cnf(subsets_axiom1, hypothesis, subset(X3, X4) | member(member_of_1_not_of_2(X3,X4), X3)).\n",
      "cnf(subsets_axiom2, hypothesis, ~member(member_of_1_not_of_2(X5,X6), X6) | subset(X5, X6)).\n",
      "cnf(set_equal_sets_are_subsets1, hypothesis, ~equal_sets(X7, X8) | subset(X7, X8)).\n",
      "cnf(set_equal_sets_are_subsets2, hypothesis, ~equal_sets(X9, X10) | subset(X10, X9)).\n",
      "cnf(subsets_are_set_equal_sets, hypothesis, ~subset(X11, X12) | ~subset(X12, X11) | equal_sets(X12, X11)).\n"
     ]
    }
   ],
   "source": [
    "# during the reset a problem is chosen at random\n",
    "print(env.render())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed1377c6",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['real_obs', 'action_mask'])\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "{'class': 'Literal', 'negated': False, 'atom': {'class': 'Predicate', 'name': 'equal_sets', 'arguments': [{'class': 'Function', 'name': 'b', 'arguments': []}, {'class': 'Function', 'name': 'bb', 'arguments': []}]}}\n"
     ]
    }
   ],
   "source": [
    "# observation is a dict with two keys: \"action_mask\" and \"real_obs\"\n",
    "# \"action_mask\" is 1 for actions an agent can choose and 0 for the rest\n",
    "# \"real_obs\" is a list of dictionaries, representing logical clauses\n",
    "print(obs.keys())\n",
    "print(obs[\"action_mask\"][:20])\n",
    "print(obs[\"real_obs\"][0][\"literals\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ea3fbfd",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrete(1000)\n",
      "9.0\n",
      "9.0\n"
     ]
    }
   ],
   "source": [
    "# possible actions are indices of not processed clauses from the state\n",
    "# formally, action space is a large enough discrete\n",
    "print(env.action_space)\n",
    "# but the number of ones in the mask\n",
    "print(obs[\"action_mask\"].sum())\n",
    "# equals to number of not processed clauses\n",
    "print(sum(\n",
    "    [1.0 for clause in obs[\"real_obs\"] if not clause[\"processed\"]]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e4a1b8f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'class': 'Clause', 'literals': [{'class': 'Literal', 'negated': False, 'atom': {'class': 'Predicate', 'name': 'equal_sets', 'arguments': [{'class': 'Function', 'name': 'b', 'arguments': []}, {'class': 'Function', 'name': 'bb', 'arguments': []}]}}], 'label': 'b_equals_bb', 'birth_step': 0, 'processed': False, 'inference_parents': [], 'inference_rule': None}, {'class': 'Clause', 'literals': [{'class': 'Literal', 'negated': False, 'atom': {'class': 'Predicate', 'name': 'member', 'arguments': [{'class': 'Function', 'name': 'element_of_b', 'arguments': []}, {'class': 'Function', 'name': 'b', 'arguments': []}]}}], 'label': 'element_of_b', 'birth_step': 0, 'processed': False, 'inference_parents': [], 'inference_rule': None}, {'class': 'Clause', 'literals': [{'class': 'Literal', 'negated': True, 'atom': {'class': 'Predicate', 'name': 'member', 'arguments': [{'class': 'Function', 'name': 'element_of_b', 'arguments': []}, {'class': 'Function', 'name': 'bb', 'arguments': []}]}}], 'label': 'prov\n"
     ]
    }
   ],
   "source": [
    "# only \"ansi\" and \"human\" rendering methods are implemented\n",
    "# \"human\" (default) returns TPTP representation\n",
    "# \"ansi\" returns a JSON string representing the state\n",
    "print(env.render(\"ansi\")[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a444050d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True 1.0\n"
     ]
    }
   ],
   "source": [
    "# the package includes a simple episode function\n",
    "from gym_saturation.agent_testing import episode\n",
    "# and an example policy, selecting the shortest clause\n",
    "from gym_saturation.agent_testing import SizeAgent\n",
    "\n",
    "size_agent = SizeAgent()\n",
    "env.problem_list = [\n",
    "    files(\"gym_saturation\")\n",
    "    .joinpath(\"resources/TPTP-mock/Problems/SET/SET001-1.p\")\n",
    "]\n",
    "episode_memory = episode(env, size_agent)\n",
    "# this policy manages to solve a simple problem from TPTP\n",
    "print(episode_memory[-1].done, episode_memory[-1].reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adb3d362",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "# the proof here consists of only three steps\n",
    "# but a naïve clause size policy finds it only after 15 steps\n",
    "# a trained DL policy might have done better\n",
    "print(len(episode_memory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "629e7043",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnf(_4, hypothesis, ~subset(b, X2) | member(element_of_b, X2), inference(resolution, [], [element_of_b, membership_in_subsets])).\n",
      "cnf(_0, hypothesis, subset(b, bb), inference(resolution, [], [b_equals_bb, set_equal_sets_are_subsets1])).\n",
      "cnf(_23, hypothesis, member(element_of_b, bb), inference(resolution, [], [_0, _4])).\n",
      "cnf(_27, hypothesis, $false, inference(resolution, [], [prove_element_of_bb, _23])).\n"
     ]
    }
   ],
   "source": [
    "# one can now check the TSTP proof found\n",
    "print(env.tstp_proof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd666d5b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 25\n"
     ]
    }
   ],
   "source": [
    "# paramodulation test\n",
    "env.problem_list = [\n",
    "    files(\"gym_saturation\")\n",
    "    .joinpath(\"resources/TPTP-mock/Problems/TST/TST002-1.p\")\n",
    "]\n",
    "episode_memory = episode(env, size_agent)\n",
    "# here the proof consists of four steps\n",
    "# but a naïve policy needs 25\n",
    "print(\n",
    "    len(env.tstp_proof.split(\"\\n\")), \n",
    "    len(episode_memory)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d963a6a4",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "argv": [
    "python",
    "-m",
    "ipykernel_launcher",
    "-f",
    "{connection_file}"
   ],
   "display_name": "Python 3",
   "env": null,
   "interrupt_mode": "signal",
   "language": "python",
   "metadata": null,
   "name": "python3"
  },
  "name": "example.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
